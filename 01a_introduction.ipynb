{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01a_introduction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM7xuWnxFlk01ORbeQg/D/r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amosdst/tensorflow_practices/blob/master/01a_introduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1O3sPwXPn2H",
        "colab_type": "text"
      },
      "source": [
        "# TensorFlow 2 Practices\n",
        "\n",
        "Copyright 2020 Amos Tsai (amosdst@gmail.com)\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaSQFe0cMIBl",
        "colab_type": "code",
        "outputId": "c385ca77-f427-4443-a48b-8f91172001f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "import sys\n",
        "import os\n",
        "import numpy\n",
        "import time\n",
        "import enum\n",
        "from enum import IntEnum\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "print('tensor-flow version : %s\\n' % tf.__version__)\n",
        "\n",
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor-flow version : 2.2.0\n",
            "\n",
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 15489696725261192336\n",
            ", name: \"/device:XLA_CPU:0\"\n",
            "device_type: \"XLA_CPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 2183191644341848762\n",
            "physical_device_desc: \"device: XLA_CPU device\"\n",
            "]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScT8ZtE3O9Tx",
        "colab_type": "code",
        "outputId": "46dc886b-5f07-480f-e721-e1f488637989",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "# ----------------------------------------------------------------------------\n",
        "# Load and prepare the MNIST dataset.\n",
        "#\n",
        "# refs ...\n",
        "#   https://keras.io/api/datasets/\n",
        "#   https://www.tensorflow.org/api_docs/python/tf/keras/datasets/mnist/load_data\n",
        "#   http://yann.lecun.com/exdb/mnist/\n",
        "#\n",
        "\n",
        "# tf.keras.datasets.mnist.load_data()\n",
        "#\n",
        "# Arguments\n",
        "#\n",
        "#   path \tpath where to cache the dataset locally (relative to ~/.keras/datasets).\n",
        "#\n",
        "# Returns\n",
        "#\n",
        "#   Tuple of Numpy arrays: (x_train, y_train), (x_test, y_test).\n",
        "#\n",
        "#   x_train, x_test: uint8 arrays of grayscale image data with shapes (num_samples, 28, 28).\n",
        "#\n",
        "#   y_train, y_test: uint8 arrays of digit labels (integers in range 0-9) with shapes (num_samples,).\n",
        "#\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "print('x_train shape = {}'.format(x_train.shape))\n",
        "print('y_train shape = {}'.format(y_train.shape))\n",
        "\n",
        "print('x_test shape  = {}'.format(x_test.shape))\n",
        "print('y_test shape  = {}'.format(y_test.shape))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "x_train shape = (60000, 28, 28)\n",
            "y_train shape = (60000,)\n",
            "x_test shape  = (10000, 28, 28)\n",
            "y_test shape  = (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kc3RFommPF4c",
        "colab_type": "code",
        "outputId": "dc85d4cc-82ee-4fad-bdd1-055da5bedfdd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        }
      },
      "source": [
        "# ----------------------------------------------------------------------------\n",
        "# A Typical Feed-Forward Network\n",
        "#\n",
        "# keras documentation\n",
        "#\n",
        "#  https://keras.io\n",
        "#\n",
        "#  API (models)\n",
        "#    https://keras.io/api/models/\n",
        "#  API (layers)\n",
        "#    https://keras.io/api/layers/\n",
        "#  API (training)\n",
        "#    https://keras.io/api/models/model_training_apis/\n",
        "#  API (model saving)\n",
        "#    https://keras.io/api/models/model_saving_apis/\n",
        "#\n",
        "# callable classes\n",
        "#\n",
        "#  keras layer objects are callables and are used to bind to the layer given in its argument\n",
        "#  (https://treyhunner.com/2019/04/is-it-a-class-or-a-function-its-a-callable/)\n",
        "#\n",
        "# shapes\n",
        "#\n",
        "#  'Input'\n",
        "#    shape : a shape tuple without the batch size\n",
        "#\n",
        "#    # keras.Input(shape = (x_train.shape[1] * x_train.shape[2]), dtype = tf.float32)\n",
        "#    #  => Out[14]: <tf.Tensor 'input_7:0' shape=(None, 784) dtype=float32>\n",
        "#\n",
        "#    # keras.Input(shape = (x_train.shape[1], x_train.shape[2]), dtype = tf.float32)\n",
        "#    #  => Out[13]: <tf.Tensor 'input_6:0' shape=(None, 28, 28) dtype=float32>\n",
        "#\n",
        "#  'Dense'\n",
        "#    input shape  : (batch_size, ..., input_dim) e.g., (batch_size, input_dim)\n",
        "#    output shape : (batch_size, ..., units)     e.g., (batch_size, units)\n",
        "#    activation   : https://keras.io/api/layers/activations/\n",
        "#                   relu, sigmoid, softmax, softplus, softsign, tanh, selu, elu, exponential(...)\n",
        "#\n",
        "# activation\n",
        "#\n",
        "#  - activation is implemented as layer classes in keras, and is ...\n",
        "#      instantiated via activation functions, or\n",
        "#      passed as a literal string asking the layer object to instantiate it for the client\n",
        "#\n",
        "#  - activation (argument) is None by default for certain amount of layer class\n",
        "#      care should be taken when composing model layers\n",
        "#\n",
        "# Q1:\n",
        "#  - The number of nodes in the input layer does not need to match the shape of the input vector.\n",
        "#  - For a 10 nodes inputs layer and a 13 element input vector, there will be 130 connections between the\n",
        "#    input vector and the input layer.\n",
        "#  - It looks there are no weighting and bias values within the connections between the input vector and\n",
        "#    the input layer, since there is no associated trainable parameters in it's model summary.\n",
        "#\n",
        "# Q2:\n",
        "#  - The accuracy value of the training report differs greatly in between the two cases that the 'Dropout'\n",
        "#    layer was placed before and after the final 'Dense' layer.  It looks the placement of the dropout layer\n",
        "#    do affect the final training accuracy, and maybe the training time.  Refer to the 'hint[1]' section\n",
        "#    bellow.\n",
        "#  - Is there any generic way to state or any quantitative measurement schemes to tell 'what is a good\n",
        "#    training result or a good performance' ?\n",
        "#\n",
        "import tensorflow.keras as keras\n",
        "\n",
        "class LOCAL_MODELING_SCHEME(IntEnum) :\n",
        "    SEQUENTIAL = 1\n",
        "    FUNCTIONAL = 2\n",
        "\n",
        "modeling_scheme = LOCAL_MODELING_SCHEME.SEQUENTIAL\n",
        "#modeling_scheme = LOCAL_MODELING_SCHEME.FUNCTIONAL\n",
        "\n",
        "batch_size = 5\n",
        "\n",
        "if (modeling_scheme == LOCAL_MODELING_SCHEME.SEQUENTIAL) :\n",
        "\n",
        "    # ----------------------------------------------------------------------------\n",
        "    # The Sequential API Approach\n",
        "\n",
        "    print('\\nSequential Modeling ...\\n')\n",
        "\n",
        "    # the model\n",
        "    model = keras.Sequential()\n",
        "\n",
        "    # the input layers\n",
        "    model.add(keras.Input(shape = (x_train.shape[1], x_train.shape[2]), batch_size = batch_size))\n",
        "    model.add(keras.layers.Flatten(data_format = 'channels_last'))\n",
        "    #model.add(keras.layers.Dense(100, input_shape = (batch_size, x_train.shape[1] * x_train.shape[2]), activation = 'relu'))\n",
        "    #model.add(keras.layers.Dense(100, activation = 'relu'))\n",
        "    model.add(keras.layers.Dense(100, activation = 'relu'))\n",
        "\n",
        "    # the hidden layers\n",
        "    model.add(keras.layers.Dense(200, activation = 'sigmoid'))\n",
        "\n",
        "    # the output layer\n",
        "    #  hint: accuracy was increased when the 'Dropout' layer was placed before the final 'Dense' layer\n",
        "    #        see 'hint[1]' comments at the training section bellow\n",
        "    #model.add(keras.layers.Dropout(0.2))\n",
        "    model.add(keras.layers.Dense(10))\n",
        "    model.add(keras.layers.Softmax())\n",
        "\n",
        "    # Model: \"sequential\"\n",
        "    # _________________________________________________________________\n",
        "    # Layer (type)                 Output Shape              Param #\n",
        "    # =================================================================\n",
        "    # flatten (Flatten)            (5, 784)                  0\n",
        "    # _________________________________________________________________\n",
        "    # dense (Dense)                (5, 100)                  78500\n",
        "    # _________________________________________________________________\n",
        "    # dense_1 (Dense)              (5, 200)                  20200\n",
        "    # _________________________________________________________________\n",
        "    # dense_2 (Dense)              (5, 10)                   2010\n",
        "    # _________________________________________________________________\n",
        "    # dropout (Dropout)            (5, 10)                   0\n",
        "    # _________________________________________________________________\n",
        "    # softmax (Softmax)            (5, 10)                   0\n",
        "    # =================================================================\n",
        "    # Total params: 100,710\n",
        "    # Trainable params: 100,710\n",
        "    # Non-trainable params: 0\n",
        "    #\n",
        "    model.summary()\n",
        "\n",
        "elif (modeling_scheme == LOCAL_MODELING_SCHEME.FUNCTIONAL) :\n",
        "\n",
        "    # ----------------------------------------------------------------------------\n",
        "    # The Functional API Approach\n",
        "\n",
        "    print('\\nFunctional Modeling ...\\n')\n",
        "\n",
        "    # the input layers\n",
        "    in_data    = keras.Input(shape = (x_train.shape[1], x_train.shape[2]), batch_size = batch_size)\n",
        "    in_vector  = keras.layers.Flatten(data_format = 'channels_last')(in_data)\n",
        "    in_layer   = keras.layers.Dense(100)(in_vector)\n",
        "    in_layer_f = keras.activations.relu(in_layer)\n",
        "\n",
        "    # the hidden layers\n",
        "    h_layer    = keras.layers.Dense(200, activation = 'sigmoid')(in_layer_f)\n",
        "\n",
        "    # the output layers\n",
        "    out_drop   = keras.layers.Dropout(rate = 0.2)(h_layer)\n",
        "    out_layer  = keras.layers.Dense(10, activation = 'softmax')(out_drop)\n",
        "\n",
        "    # the model\n",
        "    model = keras.Model(in_data, out_layer)\n",
        "\n",
        "    # Model: \"model\"\n",
        "    # _________________________________________________________________\n",
        "    # Layer (type)                 Output Shape              Param #\n",
        "    # =================================================================\n",
        "    # input_1 (InputLayer)         [(5, 28, 28)]             0\n",
        "    # _________________________________________________________________\n",
        "    # flatten (Flatten)            (5, 784)                  0\n",
        "    # _________________________________________________________________\n",
        "    # dense (Dense)                (5, 100)                  78500\n",
        "    # _________________________________________________________________\n",
        "    # tf_op_layer_Relu (TensorFlow [(5, 100)]                0\n",
        "    # _________________________________________________________________\n",
        "    # dense_1 (Dense)              (5, 200)                  20200\n",
        "    # _________________________________________________________________\n",
        "    # dropout (Dropout)            (5, 200)                  0\n",
        "    # _________________________________________________________________\n",
        "    # dense_2 (Dense)              (5, 10)                   2010\n",
        "    # =================================================================\n",
        "    # Total params: 100,710\n",
        "    # Trainable params: 100,710\n",
        "    # Non-trainable params: 0\n",
        "    #\n",
        "    model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Sequential Modeling ...\n",
            "\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (5, 784)                  0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (5, 100)                  78500     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (5, 200)                  20200     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (5, 10)                   2010      \n",
            "_________________________________________________________________\n",
            "softmax (Softmax)            (5, 10)                   0         \n",
            "=================================================================\n",
            "Total params: 100,710\n",
            "Trainable params: 100,710\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bjO8hRmPLfw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ----------------------------------------------------------------------------\n",
        "# Add the Optimizer\n",
        "#\n",
        "# available losses\n",
        "#\n",
        "#   https://keras.io/api/losses/\n",
        "#\n",
        "#   probabilistic losses\n",
        "#    'binary_crossentropy'\n",
        "#    'categorical_crossentropy'\n",
        "#    'sparse_categorical_crossentropy'\n",
        "#    'poisson'\n",
        "#    'binary_crossentropy'\n",
        "#    'binary_crossentropy'\n",
        "#\n",
        "#   regression losses\n",
        "#    'mean_squared_error'\n",
        "#    'mean_absolute_error'\n",
        "#    'mean_absolute_percentage_error'\n",
        "#    'mean_squared_logarithmic_error'\n",
        "#    'cosine_similarity'\n",
        "#    'huber_loss'\n",
        "#    'log_cosh'\n",
        "#\n",
        "#   hinge losses for maximum-margin classification\n",
        "#    'hinge'\n",
        "#    'squared_hinge'\n",
        "#    'categorial_hinge'\n",
        "#\n",
        "# available optimizers\n",
        "#\n",
        "#   https://keras.io/api/optimizers/\n",
        "#\n",
        "#   id          class       description\n",
        "#   ----------  ----------  ----------------------------------------------------------------------------------\n",
        "#   'sgd'       SGD         stochastic gradient descent\n",
        "#   'rmsprop'   RMSprop     root-mean-square (moving average square root) gradient descent\n",
        "#   'adam'      Adam        a stochastic gradient descent method that is based on adaptive estimation of first-order and second-order moments\n",
        "#   'adadelta'  Adadelta    a stochastic gradient descent method that is based on adaptive learning rate per dimension to address two drawbacks: the continual decay of learning rates, and the need for a manually selected global learning rate\n",
        "#   'adagrad'   Adagrad     an optimizer with parameter-specific learning rates\n",
        "#   'adamax'    Adamax      a variant of Adam based on the infinity norm\n",
        "#   'nadam'     Nadam       Adam is essentially RMSprop with momentum, Nadam is Adam with Nesterov momentum\n",
        "#   'ftrl'      Ftrl        https://www.eecs.tufts.edu/~dsculley/papers/ad-click-prediction.pdf\n",
        "#\n",
        "\n",
        "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBvjtNYmPQF1",
        "colab_type": "code",
        "outputId": "822d3470-e705-46a8-f829-b8a3d4b9064e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "# ----------------------------------------------------------------------------\n",
        "# model training\n",
        "#\n",
        "# example output (sequential)\n",
        "#\n",
        "#  Epoch 1/5\n",
        "#  10800/10800 [==============================] - 16s 1ms/step - loss: 0.4634 - accuracy: 0.8178 - val_loss: 0.1070 - val_accuracy: 0.9665\n",
        "#  Epoch 2/5\n",
        "#  10800/10800 [==============================] - 15s 1ms/step - loss: 0.3130 - accuracy: 0.8579 - val_loss: 0.0828 - val_accuracy: 0.9743\n",
        "#  Epoch 3/5\n",
        "#  10800/10800 [==============================] - 14s 1ms/step - loss: 0.2780 - accuracy: 0.8689 - val_loss: 0.0774 - val_accuracy: 0.9777\n",
        "#  Epoch 4/5\n",
        "#  10800/10800 [==============================] - 14s 1ms/step - loss: 0.2593 - accuracy: 0.8724 - val_loss: 0.0902 - val_accuracy: 0.9747\n",
        "#  Epoch 5/5\n",
        "#  10800/10800 [==============================] - 14s 1ms/step - loss: 0.2440 - accuracy: 0.8781 - val_loss: 0.0863 - val_accuracy: 0.9770\n",
        "#  Out[12]: <tensorflow.python.keras.callbacks.History at 0x7f339c0df080>\n",
        "#\n",
        "#  Process finished with exit code 0\n",
        "\n",
        "# example output (functional)\n",
        "#\n",
        "#  Epoch 1/5\n",
        "#  10800/10800 [==============================] - 15s 1ms/step - loss: 0.2507 - accuracy: 0.9229 - val_loss: 0.1062 - val_accuracy: 0.9685\n",
        "#  Epoch 2/5\n",
        "#  10800/10800 [==============================] - 15s 1ms/step - loss: 0.1115 - accuracy: 0.9662 - val_loss: 0.0891 - val_accuracy: 0.9723\n",
        "#  Epoch 3/5\n",
        "#  10800/10800 [==============================] - 15s 1ms/step - loss: 0.0795 - accuracy: 0.9752 - val_loss: 0.0913 - val_accuracy: 0.9718\n",
        "#  Epoch 4/5\n",
        "#  10800/10800 [==============================] - 15s 1ms/step - loss: 0.0635 - accuracy: 0.9803 - val_loss: 0.0756 - val_accuracy: 0.9780\n",
        "#  Epoch 5/5\n",
        "#  10800/10800 [==============================] - 15s 1ms/step - loss: 0.0511 - accuracy: 0.9835 - val_loss: 0.0724 - val_accuracy: 0.9817\n",
        "#\n",
        "#  Process finished with exit code 0\n",
        "#\n",
        "\n",
        "#x_train = x_train.astype(numpy.float32)\n",
        "\n",
        "model.fit(x_train, y_train, epochs = 5, batch_size = batch_size, validation_split = 0.1, verbose = 1)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "10800/10800 [==============================] - 24s 2ms/step - loss: 0.2272 - accuracy: 0.9321 - val_loss: 0.1051 - val_accuracy: 0.9668\n",
            "Epoch 2/5\n",
            "10800/10800 [==============================] - 22s 2ms/step - loss: 0.0983 - accuracy: 0.9689 - val_loss: 0.0837 - val_accuracy: 0.9757\n",
            "Epoch 3/5\n",
            "10800/10800 [==============================] - 25s 2ms/step - loss: 0.0697 - accuracy: 0.9776 - val_loss: 0.0739 - val_accuracy: 0.9778\n",
            "Epoch 4/5\n",
            "10800/10800 [==============================] - 24s 2ms/step - loss: 0.0532 - accuracy: 0.9831 - val_loss: 0.0814 - val_accuracy: 0.9767\n",
            "Epoch 5/5\n",
            "10800/10800 [==============================] - 24s 2ms/step - loss: 0.0440 - accuracy: 0.9854 - val_loss: 0.0979 - val_accuracy: 0.9743\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7faf7459e390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nXPoDOnPgFJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# hint[1] accuracy was increased when the 'Dropout' layer was placed before the 'final 'Dense' output layer\n",
        "#\n",
        "# case 1 (lower accuracy value)\n",
        "#\n",
        "#  - the 'Dropout' layer was placed after the final 'Dense' output layer\n",
        "#\n",
        "#      model.add(keras.layers.Dense(10))\n",
        "#      model.add(keras.layers.Dropout(0.2))\n",
        "#      model.add(keras.layers.Softmax())\n",
        "#\n",
        "#  - model summary and training briefing\n",
        "#\n",
        "#      Model: \"sequential\"\n",
        "#      _________________________________________________________________\n",
        "#      Layer (type)                 Output Shape              Param #\n",
        "#      =================================================================\n",
        "#      flatten (Flatten)            (5, 784)                  0\n",
        "#      _________________________________________________________________\n",
        "#      dense (Dense)                (5, 100)                  78500\n",
        "#      _________________________________________________________________\n",
        "#      dense_1 (Dense)              (5, 200)                  20200\n",
        "#      _________________________________________________________________\n",
        "#      dense_2 (Dense)              (5, 10)                   2010\n",
        "#      _________________________________________________________________\n",
        "#      dropout (Dropout)            (5, 10)                   0\n",
        "#      _________________________________________________________________\n",
        "#      softmax (Softmax)            (5, 10)                   0\n",
        "#      =================================================================\n",
        "#      Total params: 100,710\n",
        "#      Trainable params: 100,710\n",
        "#      Non-trainable params: 0\n",
        "#\n",
        "#      Epoch 1/5\n",
        "#      10800/10800 [==============================] - 16s 1ms/step - loss: 0.4634 - accuracy: 0.8178 - val_loss: 0.1070 - val_accuracy: 0.9665\n",
        "#      Epoch 2/5\n",
        "#      10800/10800 [==============================] - 15s 1ms/step - loss: 0.3130 - accuracy: 0.8579 - val_loss: 0.0828 - val_accuracy: 0.9743\n",
        "#      Epoch 3/5\n",
        "#      10800/10800 [==============================] - 14s 1ms/step - loss: 0.2780 - accuracy: 0.8689 - val_loss: 0.0774 - val_accuracy: 0.9777\n",
        "#      Epoch 4/5\n",
        "#      10800/10800 [==============================] - 14s 1ms/step - loss: 0.2593 - accuracy: 0.8724 - val_loss: 0.0902 - val_accuracy: 0.9747\n",
        "#      Epoch 5/5\n",
        "#      10800/10800 [==============================] - 14s 1ms/step - loss: 0.2440 - accuracy: 0.8781 - val_loss: 0.0863 - val_accuracy: 0.9770\n",
        "#      Out[12]: <tensorflow.python.keras.callbacks.History at 0x7f339c0df080>\n",
        "#\n",
        "# case 2 (higher accuracy value)\n",
        "#\n",
        "#  - the 'Dropout' layer was placed before the final 'Dense' output layer\n",
        "#\n",
        "#      model.add(keras.layers.Dropout(0.2))\n",
        "#      model.add(keras.layers.Dense(10))\n",
        "#      model.add(keras.layers.Softmax())\n",
        "#\n",
        "#  - model summary and training briefing\n",
        "#\n",
        "#      Model: \"sequential\"\n",
        "#      _________________________________________________________________\n",
        "#      Layer (type)                 Output Shape              Param #\n",
        "#      =================================================================\n",
        "#      flatten (Flatten)            (5, 784)                  0\n",
        "#      _________________________________________________________________\n",
        "#      dense (Dense)                (5, 100)                  78500\n",
        "#      _________________________________________________________________\n",
        "#      dense_1 (Dense)              (5, 200)                  20200\n",
        "#      _________________________________________________________________\n",
        "#      dropout (Dropout)            (5, 200)                  0\n",
        "#      _________________________________________________________________\n",
        "#      dense_2 (Dense)              (5, 10)                   2010\n",
        "#      _________________________________________________________________\n",
        "#      softmax (Softmax)            (5, 10)                   0\n",
        "#      =================================================================\n",
        "#      Total params: 100,710\n",
        "#      Trainable params: 100,710\n",
        "#      Non-trainable params: 0\n",
        "#\n",
        "#      Epoch 1/5\n",
        "#      10800/10800 [==============================] - 15s 1ms/step - loss: 0.2472 - accuracy: 0.9251 - val_loss: 0.1285 - val_accuracy: 0.9620\n",
        "#      Epoch 2/5\n",
        "#      10800/10800 [==============================] - 14s 1ms/step - loss: 0.1096 - accuracy: 0.9664 - val_loss: 0.0842 - val_accuracy: 0.9730\n",
        "#      Epoch 3/5\n",
        "#      10800/10800 [==============================] - 14s 1ms/step - loss: 0.0789 - accuracy: 0.9763 - val_loss: 0.0779 - val_accuracy: 0.9772\n",
        "#      Epoch 4/5\n",
        "#      10800/10800 [==============================] - 14s 1ms/step - loss: 0.0625 - accuracy: 0.9803 - val_loss: 0.1003 - val_accuracy: 0.9713\n",
        "#      Epoch 5/5\n",
        "#      10800/10800 [==============================] - 15s 1ms/step - loss: 0.0499 - accuracy: 0.9844 - val_loss: 0.0752 - val_accuracy: 0.9785\n",
        "#\n",
        "#      Process finished with exit code 0\n",
        "#\n",
        "# case 2 (also higher accuracy value)\n",
        "#\n",
        "#  - no 'Dropout' layer\n",
        "#\n",
        "#      model.add(keras.layers.Dense(10))\n",
        "#      model.add(keras.layers.Softmax())\n",
        "#\n",
        "#  - model summary and training briefing\n",
        "#\n",
        "#      Model: \"sequential\"\n",
        "#      _________________________________________________________________\n",
        "#      Layer (type)                 Output Shape              Param #\n",
        "#      =================================================================\n",
        "#      flatten (Flatten)            (5, 784)                  0\n",
        "#      _________________________________________________________________\n",
        "#      dense (Dense)                (5, 100)                  78500\n",
        "#      _________________________________________________________________\n",
        "#      dense_1 (Dense)              (5, 200)                  20200\n",
        "#      _________________________________________________________________\n",
        "#      dense_2 (Dense)              (5, 10)                   2010\n",
        "#      _________________________________________________________________\n",
        "#      softmax (Softmax)            (5, 10)                   0\n",
        "#      =================================================================\n",
        "#      Total params: 100,710\n",
        "#      Trainable params: 100,710\n",
        "#      Non-trainable params: 0\n",
        "#\n",
        "#      Epoch 1/5\n",
        "#      10800/10800 [==============================] - 14s 1ms/step - loss: 0.2307 - accuracy: 0.9301 - val_loss: 0.1162 - val_accuracy: 0.9650\n",
        "#      Epoch 2/5\n",
        "#      10800/10800 [==============================] - 14s 1ms/step - loss: 0.1017 - accuracy: 0.9684 - val_loss: 0.0912 - val_accuracy: 0.9697\n",
        "#      Epoch 3/5\n",
        "#      10800/10800 [==============================] - 14s 1ms/step - loss: 0.0728 - accuracy: 0.9766 - val_loss: 0.0988 - val_accuracy: 0.9700\n",
        "#      Epoch 4/5\n",
        "#      10800/10800 [==============================] - 14s 1ms/step - loss: 0.0548 - accuracy: 0.9823 - val_loss: 0.0756 - val_accuracy: 0.9787\n",
        "#      Epoch 5/5\n",
        "#      10800/10800 [==============================] - 14s 1ms/step - loss: 0.0438 - accuracy: 0.9860 - val_loss: 0.0762 - val_accuracy: 0.9795\n",
        "#\n",
        "#      Process finished with exit code 0\n",
        "#\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}